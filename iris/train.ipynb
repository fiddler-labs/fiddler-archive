{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "simple_iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07F53qk5pBz2",
        "colab_type": "text"
      },
      "source": [
        "# Intro\n",
        "This notebook creates a simple Iris classification model to allow us to test multiclass classification predictions and explanations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzE0ZW22pBz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "import pickle\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.datasets\n",
        "import sklearn.model_selection\n",
        "import sklearn.linear_model\n",
        "\n",
        "# import the Fiddler package\n",
        "import fiddler as fdl\n",
        "\n",
        "DELETE_ASSETS = True # determines if model assets should be stored or removed after upload\n",
        "DATASET_ID = 'iris'\n",
        "PROJECT_ID = 'iris_classification'\n",
        "MODEL_ID = 'logreg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTt6YXaBVzAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!conda install --yes pyyaml\n",
        "import yaml # may come included with Python, depending on your setup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYm9qqNpp_zp",
        "colab_type": "text"
      },
      "source": [
        "**Create a temporary local directory**</br>\n",
        "We will use this directory to store related model files so that we canupload them to the server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKM2Li0Pp_K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = os.path.join(os.getcwd(), r'model_assets')\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "   os.makedirs(MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EP4hOU2qizb",
        "colab_type": "text"
      },
      "source": [
        "**Set up the Fiddler Client**</br>\n",
        "This client will be used to access server side functionality such as fetching our dataset and uploading our model artifacts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikvGa3WpBz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up your Fiddler connection\n",
        "\n",
        "# NOTE: typically the API url for your running instance of Fiddler will be \"https://dev.fiddler.ai\" (or \"http://localhost:4100\" for onebox)\n",
        "url = os.getenv('FIDDLER_URL')\n",
        "\n",
        "# see <Fiddler URL>/settings/credentials to find, create, or change this token\n",
        "token = os.getenv('FIDDLER_API_TOKEN')\n",
        "\n",
        "# see <Fiddler URL>/settings/general to find this id (listed as \"Organization Name\")\n",
        "org_id = 'onebox'\n",
        "\n",
        "fiddler_api = fdl.FiddlerApi(url=url, org_id=org_id, auth_token=token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6P81f5bpBz-",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a739ef7-3df0-41ed-864e-118f8e342a0b"
      },
      "source": [
        "iris = fiddler_api.get_dataset(\n",
        "    dataset_id=DATASET_ID,\n",
        "    splits= [\"train\", \"test\"] # fetch the two necessary splits of the dataset\n",
        ")\n",
        "\n",
        "train_df, test_df = iris[\"train\"], iris[\"test\"]\n",
        "print(train_df.shape, test_df.shape)\n",
        "train_df.sample(5, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 5) (30, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>7.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "114                5.8               2.8                5.1               2.4   \n",
              "62                 6.0               2.2                4.0               1.0   \n",
              "33                 5.5               4.2                1.4               0.2   \n",
              "107                7.3               2.9                6.3               1.8   \n",
              "7                  5.0               3.4                1.5               0.2   \n",
              "\n",
              "     species  \n",
              "114        2  \n",
              "62         1  \n",
              "33         0  \n",
              "107        2  \n",
              "7          0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPnzzC83pB0B",
        "colab_type": "text"
      },
      "source": [
        "<strong>Setting up the dataset</strong></br>\n",
        "We want to ensure that the columns we wish to use as feature vectors are clearly set aside,\n",
        "and that our target column is distinctly noted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4SEUTaWpB0D",
        "colab_type": "code",
        "colab": {},
        "outputId": "622ae6bc-46ce-4a28-add1-c2f3c54c98d5"
      },
      "source": [
        "target = \"species\" # prediciton target\n",
        "features = list(train_df.columns).remove(target) # remove target column from training data\n",
        "\n",
        "cls = sklearn.linear_model.LogisticRegression(C=.1, solver='lbfgs', multi_class='multinomial', max_iter=9999)\n",
        "cls.fit(train_df.drop(columns=['species']), train_df['species'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=9999, multi_class='multinomial',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_hZnYC2pB0J",
        "colab_type": "text"
      },
      "source": [
        "<strong>ModelInfo</strong></br>\n",
        "For Fiddler to properly run and explain your model, you need to provide some information about model inputs and outputs that is not captured by the sklearn object itself. Luckily the Dataset we created above has a DatasetInfo component that can help us infer the ModelInfo of models trained on that dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whj3c34kpB0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_info = fdl.ModelInfo.from_dataset_info(\n",
        "    dataset_info=fiddler_api.get_dataset_info(DATASET_ID),\n",
        "    target=target, \n",
        "    features=features,\n",
        "    display_name='Iris LogReg',\n",
        "    description='A Logistic Regression model trained for predict the `species` feature of the iris dataset.'\n",
        ")\n",
        "model_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXJ2ynHaQkPD",
        "colab_type": "text"
      },
      "source": [
        "**ModelInfo to YAML**</br>\n",
        "We need to convert the ModelInfo object to a corresponding dictionary, and set it up to be converted to YAML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvryO-EGQvog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom method which creates a dict \n",
        "# corresponding to the expected format of a model.yaml file\n",
        "model_info = model_info.to_dict()\n",
        "\n",
        "# model.yaml contents expected to be under one 'model' key\n",
        "model_info = {\n",
        "    'model': model_info\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1jYB-YpB0L",
        "colab_type": "text"
      },
      "source": [
        "<strong>Create a model.yaml file</strong> </br>\n",
        "We want to convert the ModelInfo object into a YAML representation. </br>\n",
        "This can be done casting it to a dictionary and using PyYaml."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaJI2mjlpFhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write the yaml to a model.yaml file\n",
        "YAML_PATH = os.path.join(MODEL_DIR, 'model.yaml')\n",
        "with open(YAML_PATH, 'w+') as outfile:\n",
        "    yaml.dump(model_info, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIoHNGvOrfm-",
        "colab_type": "text"
      },
      "source": [
        "<strong>Saving the model</strong> </br>\n",
        "The model needs to be binarized using a Python PKL file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPwq4t-pB0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the pickled model\n",
        "PKL_PATH = os.path.join(MODEL_DIR, 'model.pkl')\n",
        "with open(PKL_PATH, 'wb+') as pkl_file:\n",
        "    pickle.dump(cls, pkl_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGeb6UmusIm-",
        "colab_type": "text"
      },
      "source": [
        "<strong>Creating a package.py</strong> </br>\n",
        "The following cell is exported to a `package.py` file using the `%%writefile` action. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ux80g2NsdH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PKG_PATH = os.path.join(MODEL_DIR, 'package.py')\n",
        "with open(PKG_PATH, 'w+') as fp: # create an empty package.py\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8LTn4edsE2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20e56e8f-fd4a-47aa-e9bf-73de6a4fd42a"
      },
      "source": [
        "%%writefile $PKG_PATH\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn_wrapper import SimpleSklearnModel\n",
        "\n",
        "\n",
        "PACKAGE_PATH = Path(__file__).parent\n",
        "MODEL_FILE_NAME = 'model.pkl'\n",
        "PRED_COLUMN_NAMES = ['setosa', 'versicolor', 'virginica']\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    return SimpleSklearnModel(PACKAGE_PATH / MODEL_FILE_NAME,\n",
        "                              PRED_COLUMN_NAMES, is_classifier=True,\n",
        "                              is_multiclass=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/model_assets/package.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuv8WSYtuKNk",
        "colab_type": "text"
      },
      "source": [
        "**Upload the model assets**</br>\n",
        "With all of our files in place, we will use the Fiddler client to upload them as a package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQDBHPxvuGWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fiddler_api.upload_model_package(\n",
        "    artifact_path=MODEL_DIR, # expects a model.yaml, package.py, and model.pkl\n",
        "    project_id=PROJECT_ID,\n",
        "    model_id=MODEL_ID\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdNvP-Q-7QPY",
        "colab_type": "text"
      },
      "source": [
        "**Testing the model**</br>\n",
        "To be sure that the model was successfully uplaoded, let's run some predicitons on the first ten rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA6XXlpy7Pat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = fiddler_api.run_model(\n",
        "    project_id=PROJECT_ID,\n",
        "    model_id=MODEL_ID,\n",
        "    df=train_df.head(10)\n",
        ")\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQWTiba4R0N2",
        "colab_type": "text"
      },
      "source": [
        "**Clean up assets folder**</br>\n",
        "Since we succesfully uploaded our model using the Fiddler client, we can remove the local directory storing our model assets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOEK2-IqR-H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if DELETE_ASSETS:\n",
        "  shutil.rmtree(MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
